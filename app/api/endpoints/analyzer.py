import os
import whisper
import subprocess
from moviepy.editor import VideoFileClip
import requests
import sys
import time
from enum import Enum

VIDEO_DIR = 'download/douyin_video'
AUDIO_DIR = 'video-analyzer/audio'
OUTPUT_DIR = 'video-analyzer/output'

os.makedirs(AUDIO_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# whisper_model = whisper.load_model("base")  # ç§»é™¤åŸæœ‰çš„é¡¶å±‚åŠ è½½
whisper_model = None  # ç”¨äºæ‡’åŠ è½½

def get_whisper_model():
    global whisper_model
    if whisper_model is None:
        whisper_model = whisper.load_model("base")
    return whisper_model

class ModelConfig(Enum):
    OLLAMA_QWEN2_1_5B = {
        'model': 'ollama',
        'model_name': 'qwen2:1.5b',
        'api_key': None,
        'api_url': None
    }
    OLLAMA_QWEN3_4B = {
        'model': 'ollama',
        'model_name': 'qwen3:4b',
        'api_key': None,
        'api_url': None
    }
    OLLAMA_QWEN2_5_1_5B = {
        'model': 'ollama',
        'model_name': 'qwen2.5:1.5b',
        'api_key': None,
        'api_url': None
    }
    OLLAMA_QWEN2_5_7B = {
        'model': 'ollama',
        'model_name': 'qwen2.5:7b',
        'api_key': None,
        'api_url': None
    }
    GEMINI = {
        'model': 'gemini',
        'model_name': None,
        'api_key': 'AIzaSyAdTGRH0AxltEyN-aJF63AtHySBoKur5Go',
        'api_url': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyAdTGRH0AxltEyN-aJF63AtHySBoKur5Go'
    }
    OPENAI_GPT4O_MINI = {
        'model': 'openai',
        'model_name': 'gpt-4o-mini',
        'api_key': 'sk-JB3VXVi3JcHpz0ZIKUrJeE6rYrE03tQSmKw4NHoRPtG3wbAA',
        # 'api_url': 'https://api.openai.com/v1/chat/completions'
        'api_url': 'https://api.chatanywhere.tech/v1/chat/completions'
    }

def extract_audio(video_path, audio_path):
    print(f"[éŸ³é¢‘æå–] {video_path} -> {audio_path}")
    video = VideoFileClip(video_path)
    video.audio.write_audiofile(audio_path, verbose=False, logger=None)

def transcribe_audio(audio_path):
    print(f"[è¯­éŸ³è½¬å†™] {audio_path}")
    model = get_whisper_model()
    result = model.transcribe(audio_path, language='zh')
    return result['text']

def analyze_with_ollama(transcript_text, model_name):
    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹æ–‡å­—å†…å®¹è¿›è¡Œä¼˜åŒ–ï¼š

{transcript_text}

è¦æ±‚è¾“å‡ºï¼š
1. ä»…æ ¹æ®ä¸Šä¸‹æ–‡ï¼Œè°ƒæ•´åˆ†è¯­è¨€éš”ç¬¦
2. ä¸ºç¡®ä¿è¯­ä¹‰é€šé¡ºæƒ…å†µä¸‹ï¼Œå¯ä»¥è°ƒæ•´éƒ¨åˆ†å•è¯
3. ã€ç¦æ­¢ã€‘ç¦æ­¢æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹
"""
    print("[è°ƒç”¨ Ollama æ¨¡å‹åˆ†æ]")
    for attempt in range(10):
        try:
            result = subprocess.run(
                ["ollama", "run", model_name],
                input=prompt,
                text=True,
                capture_output=True
            )
            if result.returncode == 0 and result.stdout.strip():
                return result.stdout
            else:
                print(f"[Ollama è°ƒç”¨å¤±è´¥] ç¬¬{attempt+1}æ¬¡ï¼Œ30ç§’åé‡è¯•â€¦")
        except Exception as e:
            print(f"[Ollama è°ƒç”¨å¼‚å¸¸] ç¬¬{attempt+1}æ¬¡ï¼Œ30ç§’åé‡è¯•â€¦ é”™è¯¯: {e}")
        if attempt < 9:
            time.sleep(30)
    return "[Ollama æ¨¡å‹è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•10æ¬¡]"

def analyze_with_gemini(transcript_text, api_key, api_url):
    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘éŸ³é¢‘è½¬å†™å†…å®¹è¿›è¡Œåˆ†æï¼š

{transcript_text}

è¦æ±‚è¾“å‡ºï¼š
1. è¾“å‡ºå†…å®¹æ˜¯ç»™å­¦ç”Ÿå’Œå­¦ç”Ÿå®¶é•¿çœ‹çš„
2. è§†é¢‘å†…å®¹æ‘˜è¦ï¼ˆä¸è¶…è¿‡100å­—ï¼‰
3. æå–3ä¸ªæ ¸å¿ƒè§‚ç‚¹
4. ç»™å‡º3ä¸ªåˆé€‚çš„çŸ­è§†é¢‘è¯é¢˜æ ‡ç­¾ï¼ˆå¦‚ #å¥åº· #äº²å­ #åˆ›ä¸šï¼‰
5. ç»™å­¦ç”Ÿå’Œå®¶é•¿ä¸€å¥å»ºè®®ï¼ˆä»¥\"å»ºè®®ä½ â€¦â€¦\"å¼€å¤´ï¼‰
"""
    headers = {"Content-Type": "application/json"}
    data = {
        "contents": [
            {"parts": [{"text": prompt}]}
        ]
    }
    print("[è°ƒç”¨ Google Gemini 2.0 åˆ†æ]")
    for attempt in range(10):
        try:
            response = requests.post(api_url, headers=headers, json=data)
            if response.status_code == 200:
                result = response.json()
                try:
                    return result["candidates"][0]["content"]["parts"][0]["text"]
                except Exception as e:
                    print(f"[Gemini API è¿”å›è§£æå¤±è´¥] ç¬¬{attempt+1}æ¬¡ï¼Œ30ç§’åé‡è¯•â€¦ é”™è¯¯: {e}")
            else:
                print(f"[Gemini API è¯·æ±‚å¤±è´¥] çŠ¶æ€ç : {response.status_code} ç¬¬{attempt+1}æ¬¡ï¼Œ30ç§’åé‡è¯•â€¦")
        except Exception as e:
            print(f"[Gemini API è¯·æ±‚å¼‚å¸¸] ç¬¬{attempt+1}æ¬¡ï¼Œ30ç§’åé‡è¯•â€¦ é”™è¯¯: {e}")
        if attempt < 9:
            time.sleep(30)
    return "[Gemini API è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•10æ¬¡]"

def analyze_with_openai(transcript_text, api_key, api_url, model_name):
    """
    é€šç”¨ OpenAI Chat API è°ƒç”¨æ–¹æ³•ï¼Œæ”¯æŒä»»æ„ chat æ¨¡å‹ã€‚
    æ‰©å±• openai æ¨¡å‹æ—¶ï¼Œåªéœ€åœ¨ ModelConfig ä¸­æ–°å¢é…ç½®ï¼Œå¹¶ä¼ é€’å¯¹åº”å‚æ•°ã€‚
    """
    prompt = f"""
è¯·æ ¹æ®ä»¥ä¸‹è§†é¢‘éŸ³é¢‘è½¬å†™å†…å®¹è¿›è¡Œåˆ†æï¼š

{transcript_text}

è¦æ±‚è¾“å‡ºï¼š
1. è¾“å‡ºå†…å®¹æ˜¯ç»™å­¦ç”Ÿå’Œå­¦ç”Ÿå®¶é•¿çœ‹çš„
2. è§†é¢‘å†…å®¹æ‘˜è¦ï¼ˆä¸è¶…è¿‡100å­—ï¼‰
3. æå–3ä¸ªæ ¸å¿ƒè§‚ç‚¹
4. ç»™å‡º3ä¸ªåˆé€‚çš„çŸ­è§†é¢‘è¯é¢˜æ ‡ç­¾ï¼ˆå¦‚ #å¥åº· #äº²å­ #åˆ›ä¸šï¼‰
5. ç»™å­¦ç”Ÿå’Œå®¶é•¿ä¸€å¥å»ºè®®ï¼ˆä»¥\"å»ºè®®ä½ â€¦â€¦\"å¼€å¤´ï¼‰
"""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    data = {
        "model": model_name,
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7
    }
    print(f"[è°ƒç”¨ OpenAI {model_name} åˆ†æ]")
    for attempt in range(10):
        try:
            response = requests.post(api_url, headers=headers, json=data)
            if response.status_code == 200:
                result = response.json()
                try:
                    return result["choices"][0]["message"]["content"]
                except Exception as e:
                    print(f"[OpenAI API è¿”å›è§£æå¤±è´¥] ç¬¬{attempt+1}æ¬¡ï¼Œ30ç§’åé‡è¯•â€¦ é”™è¯¯: {e}")
            else:
                print(f"[OpenAI API è¯·æ±‚å¤±è´¥] çŠ¶æ€ç : {response.status_code} ç¬¬{attempt+1}æ¬¡ï¼Œ30ç§’åé‡è¯•â€¦")
        except Exception as e:
            print(f"[OpenAI API è¯·æ±‚å¼‚å¸¸] ç¬¬{attempt+1}æ¬¡ï¼Œ30ç§’åé‡è¯•â€¦ é”™è¯¯: {e}")
        if attempt < 9:
            time.sleep(30)
    return "[OpenAI API è°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•10æ¬¡]"

def analyze_with_model(transcript_text, model_config):
    model = model_config.value['model']
    if model == "gemini":
        return analyze_with_gemini(transcript_text, model_config.value['api_key'], model_config.value['api_url'])
    elif model == "openai":
        return analyze_with_openai(transcript_text, model_config.value['api_key'], model_config.value['api_url'], model_config.value['model_name'])
    else:
        return analyze_with_ollama(transcript_text, model_config.value['model_name'])

def process_video(file_path, model_config):
    base_name = os.path.splitext(os.path.basename(file_path))[0]
    audio_path = os.path.join(AUDIO_DIR, base_name + ".wav")
    output_path = os.path.join(OUTPUT_DIR, base_name + ".md")

    extract_audio(file_path, audio_path)
    transcript = transcribe_audio(audio_path)
    print(transcript)
    analysis = analyze_with_model(transcript, model_config)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(f"# è§†é¢‘åˆ†ææŠ¥å‘Š - {base_name}\n\n")
        f.write("## ğŸ§ éŸ³é¢‘è½¬å†™å†…å®¹ï¼š\n\n")
        f.write(transcript + "\n\n")
        f.write("## ğŸ¤– å¤§æ¨¡å‹åˆ†æç»“æœï¼š\n\n")
        f.write(analysis)
    print(f"[âœ… æŠ¥å‘Šå·²ç”Ÿæˆ] {output_path}\n")

def main(model_config: ModelConfig):
    # é€‰æ‹©æ¨¡å‹
    model_map = {
        ModelConfig.OLLAMA_QWEN3_4B: ModelConfig.OLLAMA_QWEN3_4B,
        ModelConfig.OLLAMA_QWEN2_5_1_5B: ModelConfig.OLLAMA_QWEN2_5_1_5B,
        ModelConfig.OLLAMA_QWEN2_5_7B: ModelConfig.OLLAMA_QWEN2_5_7B,
        ModelConfig.GEMINI: ModelConfig.GEMINI,
        ModelConfig.OLLAMA_QWEN2_1_5B: ModelConfig.OLLAMA_QWEN2_1_5B,
        ModelConfig.OPENAI_GPT4O_MINI: ModelConfig.OPENAI_GPT4O_MINI
    }
    if model_config not in model_map:
        print("[è­¦å‘Š] æœªçŸ¥æ¨¡å‹å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨ OLLAMA_QWEN2_1_5Bã€‚å¯é€‰å‚æ•°ï¼šollamaã€ollama-qwen2:1.5bã€ollama-qwen3:4bã€ollama-qwen2.5:1.5bã€ollama-qwen2.5:7bã€geminiã€openai")
        model_config = ModelConfig.OLLAMA_QWEN2_1_5B

    video_files = [f for f in os.listdir(VIDEO_DIR) if f.endswith((".mp4", ".MP4", ".mov"))]
    total = len(video_files)
    print(f"å…±æ£€æµ‹åˆ° {total} ä¸ªè§†é¢‘æ–‡ä»¶ã€‚\n")
    for idx, file_name in enumerate(video_files, 1):
        base_name = os.path.splitext(file_name)[0]
        output_path = os.path.join(OUTPUT_DIR, base_name + ".md")
        if os.path.exists(output_path):
            print(f"[è·³è¿‡] å·²å­˜åœ¨æŠ¥å‘Šï¼Œè·³è¿‡ï¼š{file_name}")
            continue
        print(f"[è¿›åº¦] æ­£åœ¨å¤„ç†ç¬¬ {idx}/{total} ä¸ªè§†é¢‘ï¼š{file_name}")
        video_path = os.path.join(VIDEO_DIR, file_name)
        process_video(video_path, model_config)

def analyze_video_file(file_path, model_config):
    """
    åˆ†æå•ä¸ªè§†é¢‘æ–‡ä»¶ï¼Œè¿”å›å¤§æ¨¡å‹æ€»ç»“ï¼Œå¹¶è‡ªåŠ¨åˆ é™¤éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶ã€‚
    :param file_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
    :param model_config: ModelConfig æšä¸¾
    :return: str å¤§æ¨¡å‹æ€»ç»“å†…å®¹
    """
    import shutil
    base_name = os.path.splitext(os.path.basename(file_path))[0]
    audio_path = os.path.join(AUDIO_DIR, base_name + ".wav")
    output_path = os.path.join(OUTPUT_DIR, base_name + ".md")
    try:
        extract_audio(file_path, audio_path)
        transcript = transcribe_audio(audio_path)
        summary = analyze_with_model(transcript, model_config)
        # å†™å…¥ markdown æ–‡ä»¶
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(f"# è§†é¢‘åˆ†ææŠ¥å‘Š - {base_name}\n\n")
            f.write("## ğŸ§ éŸ³é¢‘è½¬å†™å†…å®¹ï¼š\n\n")
            f.write(transcript + "\n\n")
            f.write("## ğŸ¤– å¤§æ¨¡å‹åˆ†æç»“æœï¼š\n\n")
            f.write(summary)
        return summary
    finally:
        # åˆ é™¤éŸ³é¢‘å’Œè§†é¢‘æ–‡ä»¶
        if os.path.exists(audio_path):
            os.remove(audio_path)
        if os.path.exists(file_path):
            os.remove(file_path)

if __name__ == "__main__":
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ¨¡å‹ï¼ˆç”¨æšä¸¾åï¼‰
    model_enum = ModelConfig.OLLAMA_QWEN2_5_7B
    if len(sys.argv) > 1:
        try:
            model_enum = ModelConfig[sys.argv[1]]
        except KeyError:
            print(f"[è­¦å‘Š] æœªçŸ¥æ¨¡å‹å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨ OLLAMA_QWEN2_1_5Bã€‚å¯é€‰å‚æ•°ï¼š{', '.join([m.name for m in ModelConfig])}")
    main(model_enum)
