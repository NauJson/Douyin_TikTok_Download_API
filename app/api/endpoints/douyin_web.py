from typing import List

from fastapi import APIRouter, Body, Query, Request, HTTPException  # å¯¼å…¥FastAPIç»„ä»¶
from starlette.responses import FileResponse

from app.api.models.APIResponseModel import ResponseModel, ErrorResponseModel  # å¯¼å…¥å“åº”æ¨¡å‹
from app.api.endpoints.analyzer import analyze_video_file, ModelConfig
from crawlers.douyin.web.web_crawler import DouyinWebCrawler  # å¯¼å…¥æŠ–éŸ³Webçˆ¬è™«
from crawlers.utils.utils import update_ttwid_in_cookie
from crawlers.utils.utils import extract_valid_urls
from app.api.endpoints.download import fetch_data_stream, download_file_common, config  # æ–°å¢å¯¼å…¥
import os
import aiofiles
import httpx
import yaml
import asyncio
import random
import json
from datetime import datetime
import logging
import shutil
import re


router = APIRouter()
DouyinWebCrawler = DouyinWebCrawler()


# è·å–å•ä¸ªä½œå“æ•°æ®
@router.get("/fetch_one_video", response_model=ResponseModel, summary="è·å–å•ä¸ªä½œå“æ•°æ®/Get single video data")
async def fetch_one_video(request: Request,
                          aweme_id: str = Query(example="7372484719365098803", description="ä½œå“id/Video id")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–å•ä¸ªä½œå“æ•°æ®
    ### å‚æ•°:
    - aweme_id: ä½œå“id
    ### è¿”å›:
    - ä½œå“æ•°æ®

    # [English]
    ### Purpose:
    - Get single video data
    ### Parameters:
    - aweme_id: Video id
    ### Return:
    - Video data

    # [ç¤ºä¾‹/Example]
    aweme_id = "7372484719365098803"
    """
    try:
        data = await DouyinWebCrawler.fetch_one_video(aweme_id)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–ç”¨æˆ·ä½œå“é›†åˆæ•°æ®
@router.get("/fetch_user_post_videos", response_model=ResponseModel,
            summary="è·å–ç”¨æˆ·ä¸»é¡µä½œå“æ•°æ®/Get user homepage video data")
async def fetch_user_post_videos(request: Request,
                                 sec_user_id: str = Query(
                                     example="MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE",
                                     description="ç”¨æˆ·sec_user_id/User sec_user_id"),
                                 max_cursor: int = Query(default=0, description="æœ€å¤§æ¸¸æ ‡/Maximum cursor"),
                                 count: int = Query(default=20, description="æ¯é¡µæ•°é‡/Number per page")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–ç”¨æˆ·ä¸»é¡µä½œå“æ•°æ®
    ### å‚æ•°:
    - sec_user_id: ç”¨æˆ·sec_user_id
    - max_cursor: æœ€å¤§æ¸¸æ ‡
    - count: æœ€å¤§æ•°é‡
    ### è¿”å›:
    - ç”¨æˆ·ä½œå“æ•°æ®

    # [English]
    ### Purpose:
    - Get user homepage video data
    ### Parameters:
    - sec_user_id: User sec_user_id
    - max_cursor: Maximum cursor
    - count: Maximum count number
    ### Return:
    - User video data

    # [ç¤ºä¾‹/Example]
    sec_user_id = "MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE"
    max_cursor = 0
    counts = 20
    """
    try:
        data = await DouyinWebCrawler.fetch_user_post_videos(sec_user_id, max_cursor, count)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–ç”¨æˆ·å–œæ¬¢ä½œå“æ•°æ®
@router.get("/fetch_user_like_videos", response_model=ResponseModel,
            summary="è·å–ç”¨æˆ·å–œæ¬¢ä½œå“æ•°æ®/Get user like video data")
async def fetch_user_like_videos(request: Request,
                                 sec_user_id: str = Query(
                                     example="MS4wLjABAAAAW9FWcqS7RdQAWPd2AA5fL_ilmqsIFUCQ_Iym6Yh9_cUa6ZRqVLjVQSUjlHrfXY1Y",
                                     description="ç”¨æˆ·sec_user_id/User sec_user_id"),
                                 max_cursor: int = Query(default=0, description="æœ€å¤§æ¸¸æ ‡/Maximum cursor"),
                                 counts: int = Query(default=20, description="æ¯é¡µæ•°é‡/Number per page")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–ç”¨æˆ·å–œæ¬¢ä½œå“æ•°æ®
    ### å‚æ•°:
    - sec_user_id: ç”¨æˆ·sec_user_id
    - max_cursor: æœ€å¤§æ¸¸æ ‡
    - count: æœ€å¤§æ•°é‡
    ### è¿”å›:
    - ç”¨æˆ·ä½œå“æ•°æ®

    # [English]
    ### Purpose:
    - Get user like video data
    ### Parameters:
    - sec_user_id: User sec_user_id
    - max_cursor: Maximum cursor
    - count: Maximum count number
    ### Return:
    - User video data

    # [ç¤ºä¾‹/Example]
    sec_user_id = "MS4wLjABAAAAW9FWcqS7RdQAWPd2AA5fL_ilmqsIFUCQ_Iym6Yh9_cUa6ZRqVLjVQSUjlHrfXY1Y"
    max_cursor = 0
    counts = 20
    """
    try:
        data = await DouyinWebCrawler.fetch_user_like_videos(sec_user_id, max_cursor, counts)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–ç”¨æˆ·æ”¶è—ä½œå“æ•°æ®ï¼ˆç”¨æˆ·æä¾›è‡ªå·±çš„Cookieï¼‰
@router.get("/fetch_user_collection_videos", response_model=ResponseModel,
            summary="è·å–ç”¨æˆ·æ”¶è—ä½œå“æ•°æ®/Get user collection video data")
async def fetch_user_collection_videos(request: Request,
                                       cookie: str = Query(example="YOUR_COOKIE",
                                                           description="ç”¨æˆ·ç½‘é¡µç‰ˆæŠ–éŸ³Cookie/Your web version of Douyin Cookie"),
                                       max_cursor: int = Query(default=0, description="æœ€å¤§æ¸¸æ ‡/Maximum cursor"),
                                       counts: int = Query(default=20, description="æ¯é¡µæ•°é‡/Number per page")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–ç”¨æˆ·æ”¶è—ä½œå“æ•°æ®
    ### å‚æ•°:
    - cookie: ç”¨æˆ·ç½‘é¡µç‰ˆæŠ–éŸ³Cookie(æ­¤æ¥å£éœ€è¦ç”¨æˆ·æä¾›è‡ªå·±çš„Cookie)
    - max_cursor: æœ€å¤§æ¸¸æ ‡
    - count: æœ€å¤§æ•°é‡
    ### è¿”å›:
    - ç”¨æˆ·ä½œå“æ•°æ®

    # [English]
    ### Purpose:
    - Get user collection video data
    ### Parameters:
    - cookie: User's web version of Douyin Cookie (This interface requires users to provide their own Cookie)
    - max_cursor: Maximum cursor
    - count: Maximum number
    ### Return:
    - User video data

    # [ç¤ºä¾‹/Example]
    cookie = "YOUR_COOKIE"
    max_cursor = 0
    counts = 20
    """
    try:
        data = await DouyinWebCrawler.fetch_user_collection_videos(cookie, max_cursor, counts)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–ç”¨æˆ·åˆè¾‘ä½œå“æ•°æ®
@router.get("/fetch_user_mix_videos", response_model=ResponseModel,
            summary="è·å–ç”¨æˆ·åˆè¾‘ä½œå“æ•°æ®/Get user mix video data")
async def fetch_user_mix_videos(request: Request,
                                mix_id: str = Query(example="7348687990509553679", description="åˆè¾‘id/Mix id"),
                                max_cursor: int = Query(default=0, description="æœ€å¤§æ¸¸æ ‡/Maximum cursor"),
                                counts: int = Query(default=20, description="æ¯é¡µæ•°é‡/Number per page")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–ç”¨æˆ·åˆè¾‘ä½œå“æ•°æ®
    ### å‚æ•°:
    - mix_id: åˆè¾‘id
    - max_cursor: æœ€å¤§æ¸¸æ ‡
    - count: æœ€å¤§æ•°é‡
    ### è¿”å›:
    - ç”¨æˆ·ä½œå“æ•°æ®

    # [English]
    ### Purpose:
    - Get user mix video data
    ### Parameters:
    - mix_id: Mix id
    - max_cursor: Maximum cursor
    - count: Maximum number
    ### Return:
    - User video data

    # [ç¤ºä¾‹/Example]
    url = https://www.douyin.com/collection/7348687990509553679
    mix_id = "7348687990509553679"
    max_cursor = 0
    counts = 20
    """
    try:
        data = await DouyinWebCrawler.fetch_user_mix_videos(mix_id, max_cursor, counts)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–ç”¨æˆ·ç›´æ’­æµæ•°æ®
@router.get("/fetch_user_live_videos", response_model=ResponseModel,
            summary="è·å–ç”¨æˆ·ç›´æ’­æµæ•°æ®/Get user live video data")
async def fetch_user_live_videos(request: Request,
                                 webcast_id: str = Query(example="285520721194",
                                                         description="ç›´æ’­é—´webcast_id/Room webcast_id")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–ç”¨æˆ·ç›´æ’­æµæ•°æ®
    ### å‚æ•°:
    - webcast_id: ç›´æ’­é—´webcast_id
    ### è¿”å›:
    - ç›´æ’­æµæ•°æ®

    # [English]
    ### Purpose:
    - Get user live video data
    ### Parameters:
    - webcast_id: Room webcast_id
    ### Return:
    - Live stream data

    # [ç¤ºä¾‹/Example]
    webcast_id = "285520721194"
    """
    try:
        data = await DouyinWebCrawler.fetch_user_live_videos(webcast_id)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–æŒ‡å®šç”¨æˆ·çš„ç›´æ’­æµæ•°æ®
@router.get("/fetch_user_live_videos_by_room_id",
            response_model=ResponseModel,
            summary="è·å–æŒ‡å®šç”¨æˆ·çš„ç›´æ’­æµæ•°æ®/Get live video data of specified user")
async def fetch_user_live_videos_by_room_id(request: Request,
                                            room_id: str = Query(example="7318296342189919011",
                                                                 description="ç›´æ’­é—´room_id/Room room_id")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–æŒ‡å®šç”¨æˆ·çš„ç›´æ’­æµæ•°æ®
    ### å‚æ•°:
    - room_id: ç›´æ’­é—´room_id
    ### è¿”å›:
    - ç›´æ’­æµæ•°æ®

    # [English]
    ### Purpose:
    - Get live video data of specified user
    ### Parameters:
    - room_id: Room room_id
    ### Return:
    - Live stream data

    # [ç¤ºä¾‹/Example]
    room_id = "7318296342189919011"
    """
    try:
        data = await DouyinWebCrawler.fetch_user_live_videos_by_room_id(room_id)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–ç›´æ’­é—´é€ç¤¼ç”¨æˆ·æ’è¡Œæ¦œ
@router.get("/fetch_live_gift_ranking",
            response_model=ResponseModel,
            summary="è·å–ç›´æ’­é—´é€ç¤¼ç”¨æˆ·æ’è¡Œæ¦œ/Get live room gift user ranking")
async def fetch_live_gift_ranking(request: Request,
                                  room_id: str = Query(example="7356585666190461731",
                                                       description="ç›´æ’­é—´room_id/Room room_id"),
                                  rank_type: int = Query(default=30, description="æ’è¡Œç±»å‹/Leaderboard type")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–ç›´æ’­é—´é€ç¤¼ç”¨æˆ·æ’è¡Œæ¦œ
    ### å‚æ•°:
    - room_id: ç›´æ’­é—´room_id
    - rank_type: æ’è¡Œç±»å‹ï¼Œé»˜è®¤ä¸º30ä¸ç”¨ä¿®æ”¹ã€‚
    ### è¿”å›:
    - æ’è¡Œæ¦œæ•°æ®

    # [English]
    ### Purpose:
    - Get live room gift user ranking
    ### Parameters:
    - room_id: Room room_id
    - rank_type: Leaderboard type, default is 30, no need to modify.
    ### Return:
    - Leaderboard data

    # [ç¤ºä¾‹/Example]
    room_id = "7356585666190461731"
    rank_type = 30
    """
    try:
        data = await DouyinWebCrawler.fetch_live_gift_ranking(room_id, rank_type)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# æŠ–éŸ³ç›´æ’­é—´å•†å“ä¿¡æ¯
@router.get("/fetch_live_room_product_result",
            response_model=ResponseModel,
            summary="æŠ–éŸ³ç›´æ’­é—´å•†å“ä¿¡æ¯/Douyin live room product information")
async def fetch_live_room_product_result(request: Request,
                                         cookie: str = Query(example="YOUR_COOKIE",
                                                             description="ç”¨æˆ·ç½‘é¡µç‰ˆæŠ–éŸ³Cookie/Your web version of Douyin Cookie"),
                                         room_id: str = Query(example="7356742011975715619",
                                                              description="ç›´æ’­é—´room_id/Room room_id"),
                                         author_id: str = Query(example="2207432981615527",
                                                                description="ä½œè€…id/Author id"),
                                         limit: int = Query(default=20, description="æ•°é‡/Number")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - æŠ–éŸ³ç›´æ’­é—´å•†å“ä¿¡æ¯
    ### å‚æ•°:
    - cookie: ç”¨æˆ·ç½‘é¡µç‰ˆæŠ–éŸ³Cookie(æ­¤æ¥å£éœ€è¦ç”¨æˆ·æä¾›è‡ªå·±çš„Cookieï¼Œå¦‚è·å–å¤±è´¥è¯·æ‰‹åŠ¨è¿‡ä¸€æ¬¡éªŒè¯ç )
    - room_id: ç›´æ’­é—´room_id
    - author_id: ä½œè€…id
    - limit: æ•°é‡
    ### è¿”å›:
    - å•†å“ä¿¡æ¯

    # [English]
    ### Purpose:
    - Douyin live room product information
    ### Parameters:
    - cookie: User's web version of Douyin Cookie (This interface requires users to provide their own Cookie, if the acquisition fails, please manually pass the captcha code once)
    - room_id: Room room_id
    - author_id: Author id
    - limit: Number
    ### Return:
    - Product information

    # [ç¤ºä¾‹/Example]
    cookie = "YOUR_COOKIE"
    room_id = "7356742011975715619"
    author_id = "2207432981615527"
    limit = 20
    """
    try:
        data = await DouyinWebCrawler.fetch_live_room_product_result(cookie, room_id, author_id, limit)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–æŒ‡å®šç”¨æˆ·çš„ä¿¡æ¯
@router.get("/handler_user_profile",
            response_model=ResponseModel,
            summary="è·å–æŒ‡å®šç”¨æˆ·çš„ä¿¡æ¯/Get information of specified user")
async def handler_user_profile(request: Request,
                               sec_user_id: str = Query(
                                   example="MS4wLjABAAAAW9FWcqS7RdQAWPd2AA5fL_ilmqsIFUCQ_Iym6Yh9_cUa6ZRqVLjVQSUjlHrfXY1Y",
                                   description="ç”¨æˆ·sec_user_id/User sec_user_id")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–æŒ‡å®šç”¨æˆ·çš„ä¿¡æ¯
    ### å‚æ•°:
    - sec_user_id: ç”¨æˆ·sec_user_id
    ### è¿”å›:
    - ç”¨æˆ·ä¿¡æ¯

    # [English]
    ### Purpose:
    - Get information of specified user
    ### Parameters:
    - sec_user_id: User sec_user_id
    ### Return:
    - User information

    # [ç¤ºä¾‹/Example]
    sec_user_id = "MS4wLjABAAAAW9FWcqS7RdQAWPd2AA5fL_ilmqsIFUCQ_Iym6Yh9_cUa6ZRqVLjVQSUjlHrfXY1Y"
    """
    try:
        data = await DouyinWebCrawler.handler_user_profile(sec_user_id)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–å•ä¸ªè§†é¢‘è¯„è®ºæ•°æ®
@router.get("/fetch_video_comments",
            response_model=ResponseModel,
            summary="è·å–å•ä¸ªè§†é¢‘è¯„è®ºæ•°æ®/Get single video comments data")
async def fetch_video_comments(request: Request,
                               aweme_id: str = Query(example="7372484719365098803", description="ä½œå“id/Video id"),
                               cursor: int = Query(default=0, description="æ¸¸æ ‡/Cursor"),
                               count: int = Query(default=20, description="æ•°é‡/Number")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–å•ä¸ªè§†é¢‘è¯„è®ºæ•°æ®
    ### å‚æ•°:
    - aweme_id: ä½œå“id
    - cursor: æ¸¸æ ‡
    - count: æ•°é‡
    ### è¿”å›:
    - è¯„è®ºæ•°æ®

    # [English]
    ### Purpose:
    - Get single video comments data
    ### Parameters:
    - aweme_id: Video id
    - cursor: Cursor
    - count: Number
    ### Return:
    - Comments data

    # [ç¤ºä¾‹/Example]
    aweme_id = "7372484719365098803"
    cursor = 0
    count = 20
    """
    try:
        data = await DouyinWebCrawler.fetch_video_comments(aweme_id, cursor, count)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–æŒ‡å®šè§†é¢‘çš„è¯„è®ºå›å¤æ•°æ®
@router.get("/fetch_video_comment_replies",
            response_model=ResponseModel,
            summary="è·å–æŒ‡å®šè§†é¢‘çš„è¯„è®ºå›å¤æ•°æ®/Get comment replies data of specified video")
async def fetch_video_comments_reply(request: Request,
                                     item_id: str = Query(example="7354666303006723354", description="ä½œå“id/Video id"),
                                     comment_id: str = Query(example="7354669356632638218",
                                                             description="è¯„è®ºid/Comment id"),
                                     cursor: int = Query(default=0, description="æ¸¸æ ‡/Cursor"),
                                     count: int = Query(default=20, description="æ•°é‡/Number")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–æŒ‡å®šè§†é¢‘çš„è¯„è®ºå›å¤æ•°æ®
    ### å‚æ•°:
    - item_id: ä½œå“id
    - comment_id: è¯„è®ºid
    - cursor: æ¸¸æ ‡
    - count: æ•°é‡
    ### è¿”å›:
    - è¯„è®ºå›å¤æ•°æ®

    # [English]
    ### Purpose:
    - Get comment replies data of specified video
    ### Parameters:
    - item_id: Video id
    - comment_id: Comment id
    - cursor: Cursor
    - count: Number
    ### Return:
    - Comment replies data

    # [ç¤ºä¾‹/Example]
    aweme_id = "7354666303006723354"
    comment_id = "7354669356632638218"
    cursor = 0
    count = 20
    """
    try:
        data = await DouyinWebCrawler.fetch_video_comments_reply(item_id, comment_id, cursor, count)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# ç”ŸæˆçœŸå®msToken
@router.get("/generate_real_msToken",
            response_model=ResponseModel,
            summary="ç”ŸæˆçœŸå®msToken/Generate real msToken")
async def generate_real_msToken(request: Request):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - ç”ŸæˆçœŸå®msToken
    ### è¿”å›:
    - msToken

    # [English]
    ### Purpose:
    - Generate real msToken
    ### Return:
    - msToken
    """
    try:
        data = await DouyinWebCrawler.gen_real_msToken()
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# ç”Ÿæˆttwid
@router.get("/generate_ttwid",
            response_model=ResponseModel,
            summary="ç”Ÿæˆttwid/Generate ttwid")
async def generate_ttwid(request: Request):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - ç”Ÿæˆttwid
    ### è¿”å›:
    - ttwid

    # [English]
    ### Purpose:
    - Generate ttwid
    ### Return:
    - ttwid
    """
    try:
        data = await DouyinWebCrawler.gen_ttwid()
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# ç”Ÿæˆverify_fp
@router.get("/generate_verify_fp",
            response_model=ResponseModel,
            summary="ç”Ÿæˆverify_fp/Generate verify_fp")
async def generate_verify_fp(request: Request):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - ç”Ÿæˆverify_fp
    ### è¿”å›:
    - verify_fp

    # [English]
    ### Purpose:
    - Generate verify_fp
    ### Return:
    - verify_fp
    """
    try:
        data = await DouyinWebCrawler.gen_verify_fp()
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# ç”Ÿæˆs_v_web_id
@router.get("/generate_s_v_web_id",
            response_model=ResponseModel,
            summary="ç”Ÿæˆs_v_web_id/Generate s_v_web_id")
async def generate_s_v_web_id(request: Request):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - ç”Ÿæˆs_v_web_id
    ### è¿”å›:
    - s_v_web_id

    # [English]
    ### Purpose:
    - Generate s_v_web_id
    ### Return:
    - s_v_web_id
    """
    try:
        data = await DouyinWebCrawler.gen_s_v_web_id()
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# ä½¿ç”¨æ¥å£åœ°å€ç”ŸæˆXboguså‚æ•°
@router.get("/generate_x_bogus",
            response_model=ResponseModel,
            summary="ä½¿ç”¨æ¥å£ç½‘å€ç”ŸæˆX-Boguså‚æ•°/Generate X-Bogus parameter using API URL")
async def generate_x_bogus(request: Request,
                           url: str = Query(
                               example="https://www.douyin.com/aweme/v1/web/aweme/detail/?aweme_id=7148736076176215311&device_platform=webapp&aid=6383&channel=channel_pc_web&pc_client_type=1&version_code=170400&version_name=17.4.0&cookie_enabled=true&screen_width=1920&screen_height=1080&browser_language=zh-CN&browser_platform=Win32&browser_name=Edge&browser_version=117.0.2045.47&browser_online=true&engine_name=Blink&engine_version="),
                           user_agent: str = Query(
                               example="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - ä½¿ç”¨æ¥å£ç½‘å€ç”ŸæˆX-Boguså‚æ•°
    ### å‚æ•°:
    - url: æ¥å£ç½‘å€

    # [English]
    ### Purpose:
    - Generate X-Bogus parameter using API URL
    ### Parameters:
    - url: API URL

    # [ç¤ºä¾‹/Example]
    url = "https://www.douyin.com/aweme/v1/web/aweme/detail/?aweme_id=7148736076176215311&device_platform=webapp&aid=6383&channel=channel_pc_web&pc_client_type=1&version_code=170400&version_name=17.4.0&cookie_enabled=true&screen_width=1920&screen_height=1080&browser_language=zh-CN&browser_platform=Win32&browser_name=Edge&browser_version=117.0.2045.47&browser_online=true&engine_name=Blink&engine_version=117.0.0.0&os_name=Windows&os_version=10&cpu_core_num=128&device_memory=10240&platform=PC&downlink=10&effective_type=4g&round_trip_time=100"
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
    """
    try:
        x_bogus = await DouyinWebCrawler.get_x_bogus(url, user_agent)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=x_bogus)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# ä½¿ç”¨æ¥å£åœ°å€ç”ŸæˆAboguså‚æ•°
@router.get("/generate_a_bogus",
            response_model=ResponseModel,
            summary="ä½¿ç”¨æ¥å£ç½‘å€ç”ŸæˆA-Boguså‚æ•°/Generate A-Bogus parameter using API URL")
async def generate_a_bogus(request: Request,
                           url: str = Query(
                               example="https://www.douyin.com/aweme/v1/web/aweme/detail/?device_platform=webapp&aid=6383&channel=channel_pc_web&pc_client_type=1&version_code=190500&version_name=19.5.0&cookie_enabled=true&browser_language=zh-CN&browser_platform=Win32&browser_name=Firefox&browser_online=true&engine_name=Gecko&os_name=Windows&os_version=10&platform=PC&screen_width=1920&screen_height=1080&browser_version=124.0&engine_version=122.0.0.0&cpu_core_num=12&device_memory=8&aweme_id=7372484719365098803"),
                           user_agent: str = Query(
                               example="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - ä½¿ç”¨æ¥å£ç½‘å€ç”ŸæˆA-Boguså‚æ•°
    ### å‚æ•°:
    - url: æ¥å£ç½‘å€
    - user_agent: ç”¨æˆ·ä»£ç†ï¼Œæš‚æ—¶ä¸æ”¯æŒè‡ªå®šä¹‰ï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤å€¼å³å¯ã€‚

    # [English]
    ### Purpose:
    - Generate A-Bogus parameter using API URL
    ### Parameters:
    - url: API URL
    - user_agent: User agent, temporarily does not support customization, just use the default value.

    # [ç¤ºä¾‹/Example]
    url = "https://www.douyin.com/aweme/v1/web/aweme/detail/?device_platform=webapp&aid=6383&channel=channel_pc_web&pc_client_type=1&version_code=190500&version_name=19.5.0&cookie_enabled=true&browser_language=zh-CN&browser_platform=Win32&browser_name=Firefox&browser_online=true&engine_name=Gecko&os_name=Windows&os_version=10&platform=PC&screen_width=1920&screen_height=1080&browser_version=124.0&engine_version=122.0.0.0&cpu_core_num=12&device_memory=8&aweme_id=7372484719365098803"
    user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36"
    """
    try:
        a_bogus = await DouyinWebCrawler.get_a_bogus(url, user_agent)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=a_bogus)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# æå–å•ä¸ªç”¨æˆ·id
@router.get("/get_sec_user_id",
            response_model=ResponseModel,
            summary="æå–å•ä¸ªç”¨æˆ·id/Extract single user id")
async def get_sec_user_id(request: Request,
                          url: str = Query(
                              example="https://www.douyin.com/user/MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - æå–å•ä¸ªç”¨æˆ·id
    ### å‚æ•°:
    - url: ç”¨æˆ·ä¸»é¡µé“¾æ¥
    ### è¿”å›:
    - ç”¨æˆ·sec_user_id

    # [English]
    ### Purpose:
    - Extract single user id
    ### Parameters:
    - url: User homepage link
    ### Return:
    - User sec_user_id

    # [ç¤ºä¾‹/Example]
    url = "https://www.douyin.com/user/MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE"
    """
    try:
        data = await DouyinWebCrawler.get_sec_user_id(url)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# æå–åˆ—è¡¨ç”¨æˆ·id
@router.post("/get_all_sec_user_id",
             response_model=ResponseModel,
             summary="æå–åˆ—è¡¨ç”¨æˆ·id/Extract list user id")
async def get_all_sec_user_id(request: Request,
                              url: List[str] = Body(
                                  example=[
                                      "https://www.douyin.com/user/MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE?vid=7285950278132616463",
                                      "https://www.douyin.com/user/MS4wLjABAAAAVsneOf144eGDFf8Xp9QNb1VW6ovXnNT5SqJBhJfe8KQBKWKDTWK5Hh-_i9mJzb8C",
                                      "é•¿æŒ‰å¤åˆ¶æ­¤æ¡æ¶ˆæ¯ï¼Œæ‰“å¼€æŠ–éŸ³æœç´¢ï¼ŒæŸ¥çœ‹TAçš„æ›´å¤šä½œå“ã€‚ https://v.douyin.com/idFqvUms/",
                                      "https://v.douyin.com/idFqvUms/",
                                  ],
                                  description="ç”¨æˆ·ä¸»é¡µé“¾æ¥åˆ—è¡¨/User homepage link list"
                              )):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - æå–åˆ—è¡¨ç”¨æˆ·id
    ### å‚æ•°:
    - url: ç”¨æˆ·ä¸»é¡µé“¾æ¥åˆ—è¡¨
    ### è¿”å›:
    - ç”¨æˆ·sec_user_idåˆ—è¡¨

    # [English]
    ### Purpose:
    - Extract list user id
    ### Parameters:
    - url: User homepage link list
    ### Return:
    - User sec_user_id list

    # [ç¤ºä¾‹/Example]
    ```json
    {
   "urls":[
      "https://www.douyin.com/user/MS4wLjABAAAANXSltcLCzDGmdNFI2Q_QixVTr67NiYzjKOIP5s03CAE?vid=7285950278132616463",
      "https://www.douyin.com/user/MS4wLjABAAAAVsneOf144eGDFf8Xp9QNb1VW6ovXnNT5SqJBhJfe8KQBKWKDTWK5Hh-_i9mJzb8C",
      "é•¿æŒ‰å¤åˆ¶æ­¤æ¡æ¶ˆæ¯ï¼Œæ‰“å¼€æŠ–éŸ³æœç´¢ï¼ŒæŸ¥çœ‹TAçš„æ›´å¤šä½œå“ã€‚ https://v.douyin.com/idFqvUms/",
      "https://v.douyin.com/idFqvUms/"
       ]
    }
    ```
    """
    try:
        data = await DouyinWebCrawler.get_all_sec_user_id(url)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# æå–å•ä¸ªä½œå“id
@router.get("/get_aweme_id",
            response_model=ResponseModel,
            summary="æå–å•ä¸ªä½œå“id/Extract single video id")
async def get_aweme_id(request: Request,
                       url: str = Query(example="https://www.douyin.com/video/7298145681699622182")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - æå–å•ä¸ªä½œå“id
    ### å‚æ•°:
    - url: ä½œå“é“¾æ¥
    ### è¿”å›:
    - ä½œå“id

    # [English]
    ### Purpose:
    - Extract single video id
    ### Parameters:
    - url: Video link
    ### Return:
    - Video id

    # [ç¤ºä¾‹/Example]
    url = "https://www.douyin.com/video/7298145681699622182"
    """
    try:
        data = await DouyinWebCrawler.get_aweme_id(url)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# æå–åˆ—è¡¨ä½œå“id
@router.post("/get_all_aweme_id",
             response_model=ResponseModel,
             summary="æå–åˆ—è¡¨ä½œå“id/Extract list video id")
async def get_all_aweme_id(request: Request,
                           url: List[str] = Body(
                               example=[
                                   "0.53 02/26 I@v.sE Fus:/ ä½ åˆ«å¤ªå¸…äº†éƒ‘æ¶¦æ³½# ç°åœºç‰ˆlive # éŸ³ä¹èŠ‚ # éƒ‘æ¶¦æ³½  https://v.douyin.com/iRNBho6u/ å¤åˆ¶æ­¤é“¾æ¥ï¼Œæ‰“å¼€DouéŸ³æœç´¢ï¼Œç›´æ¥è§‚çœ‹è§†é¢‘!",
                                   "https://v.douyin.com/iRNBho6u/",
                                   "https://www.iesdouyin.com/share/video/7298145681699622182/?region=CN&mid=7298145762238565171&u_code=l1j9bkbd&did=MS4wLjABAAAAtqpCx0hpOERbdSzQdjRZw-wFPxaqdbAzsKDmbJMUI3KWlMGQHC-n6dXAqa-dM2EP&iid=MS4wLjABAAAANwkJuWIRFOzg5uCpDRpMj4OX-QryoDgn-yYlXQnRwQQ&with_sec_did=1&titleType=title&share_sign=05kGlqGmR4_IwCX.ZGk6xuL0osNA..5ur7b0jbOx6cc-&share_version=170400&ts=1699262937&from_aid=6383&from_ssr=1&from=web_code_link",
                                   "https://www.douyin.com/video/7298145681699622182?previous_page=web_code_link",
                                   "https://www.douyin.com/video/7298145681699622182",
                               ],
                               description="ä½œå“é“¾æ¥åˆ—è¡¨/Video link list")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - æå–åˆ—è¡¨ä½œå“id
    ### å‚æ•°:
    - url: ä½œå“é“¾æ¥åˆ—è¡¨
    ### è¿”å›:
    - ä½œå“idåˆ—è¡¨

    # [English]
    ### Purpose:
    - Extract list video id
    ### Parameters:
    - url: Video link list
    ### Return:
    - Video id list

    # [ç¤ºä¾‹/Example]
    ```json
    {
   "urls":[
       "0.53 02/26 I@v.sE Fus:/ ä½ åˆ«å¤ªå¸…äº†éƒ‘æ¶¦æ³½# ç°åœºç‰ˆlive # éŸ³ä¹èŠ‚ # éƒ‘æ¶¦æ³½  https://v.douyin.com/iRNBho6u/ å¤åˆ¶æ­¤é“¾æ¥ï¼Œæ‰“å¼€DouéŸ³æœç´¢ï¼Œç›´æ¥è§‚çœ‹è§†é¢‘!",
       "https://v.douyin.com/iRNBho6u/",
       "https://www.iesdouyin.com/share/video/7298145681699622182/?region=CN&mid=7298145762238565171&u_code=l1j9bkbd&did=MS4wLjABAAAAtqpCx0hpOERbdSzQdjRZw-wFPxaqdbAzsKDmbJMUI3KWlMGQHC-n6dXAqa-dM2EP&iid=MS4wLjABAAAANwkJuWIRFOzg5uCpDRpMj4OX-QryoDgn-yYlXQnRwQQ&with_sec_did=1&titleType=title&share_sign=05kGlqGmR4_IwCX.ZGk6xuL0osNA..5ur7b0jbOx6cc-&share_version=170400&ts=1699262937&from_aid=6383&from_ssr=1&from=web_code_link",
       "https://www.douyin.com/video/7298145681699622182?previous_page=web_code_link",
       "https://www.douyin.com/video/7298145681699622182",
    ]
    }
    ```
    """
    try:
        data = await DouyinWebCrawler.get_all_aweme_id(url)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# æå–åˆ—è¡¨ç›´æ’­é—´å·
@router.get("/get_webcast_id",
            response_model=ResponseModel,
            summary="æå–åˆ—è¡¨ç›´æ’­é—´å·/Extract list webcast id")
async def get_webcast_id(request: Request,
                         url: str = Query(example="https://live.douyin.com/775841227732")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - æå–åˆ—è¡¨ç›´æ’­é—´å·
    ### å‚æ•°:
    - url: ç›´æ’­é—´é“¾æ¥
    ### è¿”å›:
    - ç›´æ’­é—´å·

    # [English]
    ### Purpose:
    - Extract list webcast id
    ### Parameters:
    - url: Room link
    ### Return:
    - Room id

    # [ç¤ºä¾‹/Example]
    url = "https://live.douyin.com/775841227732"
    """
    try:
        data = await DouyinWebCrawler.get_webcast_id(url)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# æå–åˆ—è¡¨ç›´æ’­é—´å·
@router.post("/get_all_webcast_id",
             response_model=ResponseModel,
             summary="æå–åˆ—è¡¨ç›´æ’­é—´å·/Extract list webcast id")
async def get_all_webcast_id(request: Request,
                             url: List[str] = Body(
                                 example=[
                                     "https://live.douyin.com/775841227732",
                                     "https://live.douyin.com/775841227732?room_id=7318296342189919011&enter_from_merge=web_share_link&enter_method=web_share_link&previous_page=app_code_link",
                                     'https://webcast.amemv.com/douyin/webcast/reflow/7318296342189919011?u_code=l1j9bkbd&did=MS4wLjABAAAAEs86TBQPNwAo-RGrcxWyCdwKhI66AK3Pqf3ieo6HaxI&iid=MS4wLjABAAAA0ptpM-zzoliLEeyvWOCUt-_dQza4uSjlIvbtIazXnCY&with_sec_did=1&use_link_command=1&ecom_share_track_params=&extra_params={"from_request_id":"20231230162057EC005772A8EAA0199906","im_channel_invite_id":"0"}&user_id=3644207898042206&liveId=7318296342189919011&from=share&style=share&enter_method=click_share&roomId=7318296342189919011&activity_info={}',
                                     "6i- Q@x.Sl 03/23 ã€é†’å­8keçš„ç›´æ’­é—´ã€‘  ç‚¹å‡»æ‰“å¼€ğŸ‘‰https://v.douyin.com/i8tBR7hX/  æˆ–é•¿æŒ‰å¤åˆ¶æ­¤æ¡æ¶ˆæ¯ï¼Œæ‰“å¼€æŠ–éŸ³ï¼Œçœ‹TAç›´æ’­",
                                     "https://v.douyin.com/i8tBR7hX/",
                                 ],
                                 description="ç›´æ’­é—´é“¾æ¥åˆ—è¡¨/Room link list")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - æå–åˆ—è¡¨ç›´æ’­é—´å·
    ### å‚æ•°:
    - url: ç›´æ’­é—´é“¾æ¥åˆ—è¡¨
    ### è¿”å›:
    - ç›´æ’­é—´å·åˆ—è¡¨

    # [English]
    ### Purpose:
    - Extract list webcast id
    ### Parameters:
    - url: Room link list
    ### Return:
    - Room id list

    # [ç¤ºä¾‹/Example]
    ```json
    {
      "urls": [
            "https://live.douyin.com/775841227732",
            "https://live.douyin.com/775841227732?room_id=7318296342189919011&enter_from_merge=web_share_link&enter_method=web_share_link&previous_page=app_code_link",
            'https://webcast.amemv.com/douyin/webcast/reflow/7318296342189919011?u_code=l1j9bkbd&did=MS4wLjABAAAAEs86TBQPNwAo-RGrcxWyCdwKhI66AK3Pqf3ieo6HaxI&iid=MS4wLjABAAAA0ptpM-zzoliLEeyvWOCUt-_dQza4uSjlIvbtIazXnCY&with_sec_did=1&use_link_command=1&ecom_share_track_params=&extra_params={"from_request_id":"20231230162057EC005772A8EAA0199906","im_channel_invite_id":"0"}&user_id=3644207898042206&liveId=7318296342189919011&from=share&style=share&enter_method=click_share&roomId=7318296342189919011&activity_info={}',
            "6i- Q@x.Sl 03/23 ã€é†’å­8keçš„ç›´æ’­é—´ã€‘  ç‚¹å‡»æ‰“å¼€ğŸ‘‰https://v.douyin.com/i8tBR7hX/  æˆ–é•¿æŒ‰å¤åˆ¶æ­¤æ¡æ¶ˆæ¯ï¼Œæ‰“å¼€æŠ–éŸ³ï¼Œçœ‹TAç›´æ’­",
            "https://v.douyin.com/i8tBR7hX/",
            ]
    }
    ```
    """
    try:
        data = await DouyinWebCrawler.get_all_webcast_id(url)
        return ResponseModel(code=200,
                             router=request.url.path,
                             data=data)
    except Exception as e:
        status_code = 400
        detail = ErrorResponseModel(code=status_code,
                                    router=request.url.path,
                                    params=dict(request.query_params),
                                    )
        raise HTTPException(status_code=status_code, detail=detail.dict())


# è·å–ç”¨æˆ·ä¸»é¡µå…¨éƒ¨è§†é¢‘ä¿¡æ¯ï¼ˆä»…è¿”å›è§†é¢‘ä¿¡æ¯åˆ—è¡¨ï¼Œä¸ä¸‹è½½ï¼‰
@router.post("/fetch_user_all_videos_brief", response_model=ResponseModel, summary="è·å–ç”¨æˆ·ä¸»é¡µå…¨éƒ¨è§†é¢‘ä¿¡æ¯ï¼ˆä»…è¿”å›è§†é¢‘ä¿¡æ¯åˆ—è¡¨ï¼Œä¸ä¸‹è½½ï¼Œå¯é€‰æ˜¯å¦ä¿å­˜åˆ°æœ¬åœ°ï¼‰/Fetch all user homepage video info (only return info list, optionally save to local)")
async def fetch_user_all_videos_brief(
    request: Request,
    url: str = Body(..., embed=True, description="ç”¨æˆ·ä¸»é¡µé“¾æ¥/User homepage url"),
    save_to_local: bool = Body(True, embed=True, description="æ˜¯å¦ä¿å­˜åˆ°æœ¬åœ°/Whether to save to local file (default: True)"),
    count: int = Body(5, embed=True, description="æ¯é¡µæ•°é‡/Number per page (default: 5)")
):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è·å–ç”¨æˆ·ä¸»é¡µå…¨éƒ¨è§†é¢‘ä¿¡æ¯ï¼ˆä»…è¿”å›è§†é¢‘ä¿¡æ¯åˆ—è¡¨ï¼Œä¸ä¸‹è½½ï¼Œå¯é€‰æ˜¯å¦ä¿å­˜åˆ°æœ¬åœ°ï¼‰
    ### å‚æ•°:
    - url: ç”¨æˆ·ä¸»é¡µé“¾æ¥
    - save_to_local: æ˜¯å¦ä¿å­˜åˆ°æœ¬åœ°ï¼Œé»˜è®¤ä¸º True
    - count: æ¯é¡µæ•°é‡ï¼Œé»˜è®¤ä¸º 5
    ### è¿”å›:
    - è§†é¢‘ä¿¡æ¯JSONæ•°ç»„

    # [English]
    ### Purpose:
    - Fetch all user homepage video info (only return info list, optionally save to local)
    ### Parameters:
    - url: User homepage url
    - save_to_local: Whether to save to local file (default: True)
    - count: Number per page (default: 5)
    ### Return:
    - Video info JSON array
    """
    try:
        # 1. è·å– sec_user_id
        sec_user_id_data = await DouyinWebCrawler.get_sec_user_id(url)
        if isinstance(sec_user_id_data, dict):
            sec_user_id = sec_user_id_data.get("sec_user_id") or sec_user_id_data.get("data") or sec_user_id_data.get("result") or sec_user_id_data
        else:
            sec_user_id = sec_user_id_data
        if not sec_user_id:
            return ErrorResponseModel(code=400, message="æœªèƒ½æå–sec_user_id", router=request.url.path, params={"url": url})

        # 2. åˆ†é¡µè·å–æ‰€æœ‰aweme_idåŠç®€è¦ä¿¡æ¯
        video_brief_list = []
        max_cursor = 0
        while True:
            delay = random.uniform(0, 1)
            await asyncio.sleep(delay)
            data = await DouyinWebCrawler.fetch_user_post_videos(sec_user_id, max_cursor, count)
            aweme_list = data.get("aweme_list", [])
            # æ–°å¢è¿›åº¦æ—¥å¿—
            logger = logging.getLogger("fetch_user_all_videos_brief")
            logger.info(f"å·²è§£æ{len(video_brief_list)}ä¸ªï¼Œæœ¬æ¬¡æ­£åœ¨è§£æ{len(aweme_list)}ä¸ª")
            if not aweme_list:
                break
            for item in aweme_list:
                aweme_id = item.get("aweme_id", "")
                desc = item.get("desc", "")
                item_title = item.get("item_title", "")
                create_time = item.get("create_time", "")
                # æ–°å¢ï¼šå°† create_time è½¬æ¢ä¸º 'YYYY-MM-DD' æ ¼å¼ï¼Œå…¼å®¹å­—ç¬¦ä¸²å’Œæ•´æ•°
                if create_time:
                    try:
                        ts = int(float(create_time))
                        # åˆ¤æ–­æ—¶é—´æˆ³æ˜¯å¦ä¸º10ä½ï¼ˆç§’ï¼‰è¿˜æ˜¯13ä½ï¼ˆæ¯«ç§’ï¼‰
                        if ts > 1e12:
                            ts = ts // 1000
                        create_time_fmt = datetime.fromtimestamp(ts).strftime('%Y-%m-%d')
                    except Exception:
                        create_time_fmt = str(create_time)
                else:
                    create_time_fmt = ''
                video_brief_list.append({
                    "create_time": create_time_fmt,
                    "aweme_id": aweme_id,
                    "desc": desc,
                    "item_title": item_title,
                })
            if not data.get("has_more"):
                break
            max_cursor = data.get("max_cursor", 0)

        # 3. å¯é€‰ï¼šä¿å­˜åˆ°æœ¬åœ° txt æ–‡ä»¶
        if save_to_local:
            # æ–°å¢ï¼šä¼˜å…ˆç”¨ç¬¬ä¸€ä¸ªè§†é¢‘çš„ä½œè€…nicknameä½œä¸ºæ–‡ä»¶å
            if video_brief_list and isinstance(video_brief_list, list):
                # é‡æ–°è·å–åŸå§‹aweme_listç¬¬ä¸€ä¸ªå…ƒç´ çš„ä½œè€…nickname
                first_aweme = None
                if 'aweme_list' in data and isinstance(data['aweme_list'], list) and len(data['aweme_list']) > 0:
                    first_aweme = data['aweme_list'][0]
                if first_aweme and 'author' in first_aweme and 'nickname' in first_aweme['author']:
                    file_nickname = first_aweme['author']['nickname']
                else:
                    file_nickname = sec_user_id
            else:
                file_nickname = sec_user_id
            # æ–‡ä»¶åå»é™¤ç‰¹æ®Šå­—ç¬¦
            file_nickname = re.sub(r'[\\/:*?"<>|\s]', '_', str(file_nickname))
            current_dir = os.path.dirname(os.path.abspath(__file__))
            # æ–°å¢ï¼šåœ¨å½“å‰ç›®å½•ä¸‹åˆ›å»º"ä½œå“é›†"æ–‡ä»¶å¤¹
            collection_dir = os.path.join(current_dir, "ä½œå“é›†")
            os.makedirs(collection_dir, exist_ok=True)
            txt_filename = f"{file_nickname}.txt"
            txt_path = os.path.join(collection_dir, txt_filename)
            with open(txt_path, 'w', encoding='utf-8') as f:
                for brief in video_brief_list:
                    f.write(json.dumps(brief, ensure_ascii=False) + '\n')

        # 4. è¿”å›è§†é¢‘ä¿¡æ¯JSONæ•°ç»„
        return ResponseModel(code=200, router=request.url.path, data=video_brief_list)
    except Exception as e:
        return ErrorResponseModel(code=500, message=str(e), router=request.url.path, params={"url": url})


# æ–°å¢ï¼šæ‰¹é‡è§£ætxtå¹¶ä¸‹è½½è§†é¢‘åˆ°æŒ‡å®šç›®å½•
@router.post("/batch_download_by_txt", response_model=ResponseModel, summary="æ‰¹é‡è§£ætxtå¹¶ä¸‹è½½è§†é¢‘/Bulk download videos by txt info")
async def batch_download_by_txt(request: Request):
    """
    è§£æapp/api/endpoints/ä½œå“é›†/å¼ é›ªå³°è€å¸ˆ.txtï¼Œ
    é€ä¸ªä¸‹è½½è§†é¢‘åˆ°/download_video/å¼ é›ªå³°è€å¸ˆ/ï¼Œ
    æ–‡ä»¶åä¸º{desc}_{åˆ›å»ºæ—¶é—´}.MP4ã€‚
    """
    logger = logging.getLogger("batch_download_by_txt")
    try:
        logger.info("å¼€å§‹æ‰¹é‡ä¸‹è½½ä»»åŠ¡")
        # 1. è¯»å–txtæ–‡ä»¶
        txt_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "ä½œå“é›†", "å¼ é›ªå³°è€å¸ˆ.txt")
        logger.info(f"å°è¯•è¯»å–txtæ–‡ä»¶: {txt_path}")
        if not os.path.exists(txt_path):
            logger.error("æœªæ‰¾åˆ°txtæ–‡ä»¶")
            return ErrorResponseModel(code=404, message="æœªæ‰¾åˆ°txtæ–‡ä»¶", router=request.url.path, params={})
        video_list = []
        with open(txt_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    video = json.loads(line)
                    video_list.append(video)
                except Exception as e:
                    logger.warning(f"è§£æè¡Œå¤±è´¥: {e}, å†…å®¹: {line}")
        logger.info(f"è¯»å–åˆ°{len(video_list)}æ¡è§†é¢‘ä¿¡æ¯")
        if not isinstance(video_list, list) or not video_list:
            logger.error("txtå†…å®¹æ ¼å¼é”™è¯¯æˆ–æ— æœ‰æ•ˆæ•°æ®")
            return ErrorResponseModel(code=400, message="txtå†…å®¹æ ¼å¼é”™è¯¯æˆ–æ— æœ‰æ•ˆæ•°æ®", router=request.url.path, params={})

        # 2. åˆ›å»ºä¸‹è½½ç›®å½•
        download_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))), 'download_video', 'å¼ é›ªå³°è€å¸ˆ')
        logger.info(f"å‡†å¤‡åˆ›å»ºä¸‹è½½ç›®å½•: {download_dir}")
        os.makedirs(download_dir, exist_ok=True)
        logger.info("ä¸‹è½½ç›®å½•å·²åˆ›å»ºæˆ–å·²å­˜åœ¨")

        # æ–°å¢ï¼šè·å–æ€»æ•°
        total_count = len(video_list)
        logger.info(f"æœ¬æ¬¡å…±éœ€ä¸‹è½½ {total_count} ä¸ªè§†é¢‘")

        # 3. ä¾æ¬¡ä¸‹è½½
        download_results = []
        for idx, video in enumerate(video_list):
            logger.info(f"æ­£åœ¨ä¸‹è½½ç¬¬ {idx+1}/{total_count} ä¸ªè§†é¢‘...")
            aweme_id = video.get('aweme_id')
            desc = video.get('desc', '')
            create_time = video.get('create_time', '')
            logger.info(f"[{idx+1}/{total_count}] å¼€å§‹å¤„ç†aweme_id: {aweme_id}")
            # ç”Ÿæˆå®‰å…¨æ–‡ä»¶å
            safe_desc = desc if desc else aweme_id
            safe_desc = safe_desc.replace('/', '_').replace('\\', '_').replace(' ', '_')
            # æ ¼å¼åŒ–åˆ›å»ºæ—¶é—´
            dt_str = str(create_time).replace('-', '') if create_time else 'unknown'
            filename = f"{safe_desc}_{dt_str}.MP4"
            file_path = os.path.join(download_dir, filename)
            # è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶
            if os.path.exists(file_path):
                logger.info(f"aweme_id: {aweme_id} æ–‡ä»¶å·²å­˜åœ¨: {filename}")
                download_results.append({"aweme_id": aweme_id, "status": "exists", "file": filename})
                continue
            # æ‹¼æ¥è§†é¢‘é“¾æ¥
            video_url = f"https://www.douyin.com/video/{aweme_id}"
            try:
                import random
                import asyncio
                # éšæœºåœé¡¿1-3ç§’
                sleep_time = random.uniform(10, 15)
                logger.info(f"aweme_id: {aweme_id} éšæœºåœé¡¿ {sleep_time:.2f} ç§’")
                await asyncio.sleep(sleep_time)
                # é‡è¯•æœºåˆ¶ï¼šæœ€å¤šé‡è¯•3æ¬¡ï¼Œæ¯æ¬¡é—´éš”5-10ç§’
                max_retries = 3
                retry_count = 0
                result = None
                while retry_count < max_retries:
                    try:
                        result = await download_file_common(request, video_url, prefix=True, with_watermark=False, config=config)
                        break
                    except Exception as e:
                        retry_count += 1
                        if retry_count >= max_retries:
                            logger.error(f"aweme_id: {aweme_id} é‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥: {e}")
                            raise e
                        sleep_time = random.uniform(20, 30)
                        logger.warning(f"aweme_id: {aweme_id} ç¬¬{retry_count}æ¬¡é‡è¯•å¤±è´¥ï¼Œç­‰å¾…{sleep_time:.2f}ç§’åé‡è¯•: {e}")
                        await asyncio.sleep(sleep_time)
                if isinstance(result, FileResponse):
                    src_path = result.path
                    logger.info(f"aweme_id: {aweme_id} ä¸‹è½½æˆåŠŸ: {filename}")
                    download_results.append({"aweme_id": aweme_id, "status": "success", "file": filename})
                elif isinstance(result, bytes):
                    async with aiofiles.open(file_path, 'wb') as f:
                        await f.write(result)
                    logger.info(f"aweme_id: {aweme_id} ä¸‹è½½æˆåŠŸ: {filename}")
                    download_results.append({"aweme_id": aweme_id, "status": "success", "file": filename})
                elif hasattr(result, 'code') and getattr(result, 'code', None) != 200:
                    logger.error(f"aweme_id: {aweme_id} ä¸‹è½½å¤±è´¥: {getattr(result, 'message', 'æœªçŸ¥é”™è¯¯')}")
                    download_results.append({"aweme_id": aweme_id, "status": "fail", "reason": getattr(result, 'message', 'æœªçŸ¥é”™è¯¯')})
                else:
                    logger.info(f"aweme_id: {aweme_id} ä¸‹è½½å®Œæˆ: {filename}")
                    download_results.append({"aweme_id": aweme_id, "status": "success", "file": filename})
            except Exception as e:
                logger.error(f"aweme_id: {aweme_id} å¤„ç†å¼‚å¸¸: {e}")
                download_results.append({"aweme_id": aweme_id, "status": "fail", "reason": str(e)})
        logger.info(f"å…¨éƒ¨å¤„ç†å®Œæˆï¼Œå…±{len(download_results)}æ¡")
        return ResponseModel(code=200, router=request.url.path, data=download_results)
    except Exception as e:
        logger.error(f"æ‰¹é‡ä¸‹è½½ä»»åŠ¡å¼‚å¸¸: {e}")
        return ErrorResponseModel(code=500, message=str(e), router=request.url.path, params={})


# æ–°å¢ï¼šè§£æå•ä¸ªæŠ–éŸ³è§†é¢‘å¹¶åˆ†æ
@router.post("/analyze_single_video", response_model=ResponseModel, summary="è§£æå•ä¸ªæŠ–éŸ³è§†é¢‘å¹¶è¾“å‡ºæ€»ç»“/Analyze single Douyin video and output summary")
async def analyze_single_video(request: Request, url: str = Body(..., embed=True, description="æŠ–éŸ³åˆ†äº«é“¾æ¥/Douyin share link")):
    """
    # [ä¸­æ–‡]
    ### ç”¨é€”:
    - è§£æå•ä¸ªæŠ–éŸ³è§†é¢‘ï¼Œè‡ªåŠ¨ä¸‹è½½ã€è½¬å†™ã€åˆ†æå¹¶è¾“å‡ºæ€»ç»“
    ### å‚æ•°:
    - url: æŠ–éŸ³åˆ†äº«é“¾æ¥
    ### è¿”å›:
    - åˆ†ææ€»ç»“å†…å®¹
    """
    import tempfile
    import importlib.util
    import sys
    import os
    try:
        # 1. è§£æåœ°å€ï¼Œæå–æœ‰æ•ˆURL
        valid_url = extract_valid_urls(url)
        if not valid_url:
            return ErrorResponseModel(code=400, message="æ— æ•ˆçš„æŠ–éŸ³é“¾æ¥", router=request.url.path, params={"url": url})
        
        # 2. è·å–aweme_id
        aweme_id = await DouyinWebCrawler.get_aweme_id(valid_url)
        if not aweme_id:
            return ErrorResponseModel(code=400, message="æ— æ³•è·å–è§†é¢‘ID", router=request.url.path, params={"url": url})
        
        # 3. ä¸‹è½½è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        temp_dir = tempfile.gettempdir()
        temp_video_path = os.path.join(temp_dir, f"douyin_{aweme_id}.mp4")
        

        
        # ç›´æ¥ç”¨download_file_commonä¸‹è½½åˆ°æŒ‡å®šè·¯å¾„
        from app.api.endpoints.download import download_file_common, config
        class DummyRequest:
            async def is_disconnected(self):
                return False
            url = type('url', (), {'path': '/analyze_single_video'})()
            query_params = {}
        dummy_request = DummyRequest()
        
        # download_file_commonè¿”å›FileResponseï¼Œéœ€å…ˆä¸‹è½½åˆ°æœ¬åœ°
        result = await download_file_common(dummy_request, valid_url, prefix=False, with_watermark=False, config=config)
        if hasattr(result, 'path') and os.path.exists(result.path):
            temp_video_path = result.path
        elif hasattr(result, 'code') and getattr(result, 'code', None) != 200:
            return result
        else:
            return ErrorResponseModel(code=500, message="è§†é¢‘ä¸‹è½½å¤±è´¥", router=request.url.path, params={"url": url})
        
        # 4. è°ƒç”¨ analyzer.py çš„ analyze_video_file æ–¹æ³•
        # é»˜è®¤ç”¨ OLLAMA_QWEN2_5_7B
        model_config = ModelConfig.OLLAMA_QWEN2_5_7B
        summary = analyze_video_file(temp_video_path, model_config)
        
        # 5. è¿”å›åˆ†æç»“æœ
        return ResponseModel(code=200, router=request.url.path, data=summary)
    except Exception as e:
        return ErrorResponseModel(code=500, message=str(e), router=request.url.path, params={"url": url})
